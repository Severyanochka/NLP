# Проект: Классификация отзывов на фильмы

## Описание

Этот проект демонстрирует процесс классификации отзывов на фильмы с использованием методов обработки естественного языка (NLP). Для этого используются библиотеки Keras, NLTK, Scikit-learn и NumPy.

Keras загружает данные и выполняет начальную обработку, обеспечивая, чтобы текстовые данные имели одинаковую длину.

NLTK обрабатывает текстовые данные, выполняя токенизацию, удаление стоп-слов и стемминг, чтобы подготовить текст для преобразования в числовые векторы.

Scikit-learn берет подготовленные текстовые данные, преобразует их в числовые векторы с помощью CountVectorizer, обучает модель с помощью MultinomialNB (алгоритм для задач классификации, теорема Байеса позволяет вычислить вероятность того, что наблюдаемый объект относится к определённому классу на основе известных данных) и оценивает ее производительность.

NumPy помогает работать с массивами данных и обеспечивает эффективные вычисления на уровне массивов.

## Основные шаги

1. **Загрузка необходимых ресурсов NLTK**  
   Загружаются пакеты NLTK для токенизации текста и удаления стоп-слов.

2. **Загрузка набора данных**  
   Используется набор данных IMDB, содержащий отзывы на фильмы в виде последовательности чисел, где числа соответствуют индексам слов в словаре. Метки для каждого отзыва указывают, является ли отзыв положительным или отрицательным.

3. **Преобразование данных**  
   Выполняется паддинг (выравнивание длины последовательностей) для обеспечения одинаковой длины всех отзывов.

4. **Декодирование текстов**  
   Оцифрованные отзывы преобразуются обратно в текст. Создается обратный словарь (индексы → слова), где индексы 0, 1, 2 и 3 зарезервированы для специальных токенов:
   - `0: <PAD>` — Паддинг токен для выравнивания длины последовательностей.
   - `1: <START>` — Токен начала последовательности.
   - `2: <UNK>` — Токен для неизвестных слов.
   - `3: <UNUSED>` — Неиспользуемый токен.

5. **Функция декодирования**  
   Для каждого индекса ищется соответствующее слово в словаре. Если индекс не найден, возвращается символ `?` как запасной вариант. Слова объединяются в строку, разделенную пробелами.

6. **Применение функции декодирования**  
   Функция декодирования применяется к обучающей и тестовой выборке, переводя набор чисел в слова.

7. **Создание множества стоп-слов**  
   Создается множество стоп-слов на английском языке для дальнейшего использования в предварительной обработке текста.

8. **Создание экземпляра стеммера**  
   Создается экземпляр класса `PorterStemmer` для применения стемминга к словам.

9. **Предварительная обработка текста**  
   Функция преобразует текст в нижний регистр, разбивает его на отдельные слова, фильтрует слова, содержащие только буквы и не являющиеся стоп-словами, применяет стемминг и объединяет слова в строку.

10. **Применение предварительной обработки**  
    Функция предварительной обработки применяется к обучающей и тестовой выборке.

11. **Векторизация текста**  
    Создается класс `CountVectorizer` для преобразования текста в числовые векторы. В обучающей выборке создается матрица частот слов, где строки представляют собой текстовые документы, а столбцы — слова из словаря. На основе этого словаря создается матрица для тестовой выборки.

12. **Создание и обучение модели**  
    Создается и обучается модель наивного байесовского классификатора (`MultinomialNB`) на тренировочных данных.

13. **Оценка модели**  
    Модель производит предсказания, и на экран выводятся данные о точности предсказания, включая метрики точности, полноты и F1-меры.

## Выводы

**Точность модели (Accuracy)**: Модель достигла точности 82.42%, что свидетельствует о хорошем общем качестве классификации. Это означает, что модель правильно классифицировала тональность текста в 82.42% случаев.

2. **Precision (Точность)**: Значения Precision для обоих классов близки к 0.82-0.83, что указывает на высокую способность модели правильно классифицировать примеры, минимизируя ложные срабатывания.

3. **Recall (Полнота)**: Значения Recall также составляют 0.82-0.83 для обоих классов, что свидетельствует о хорошем умении модели обнаруживать как положительные, так и отрицательные примеры.

4. **F1-Score**: Значения F1-Score для обоих классов находятся в пределах 0.82-0.83. Это среднее значение между Precision и Recall, которое показывает сбалансированное качество модели.

5. **Средние метрики**: Macro и Weighted Average метрики подтверждают сбалансированность модели по отношению к различным классам и её способность к равномерной классификации.

Эти результаты указывают на то, что модель демонстрирует стабильные и надежные показатели по классификации тональности текста. Возможно, дальнейшее улучшение модели может быть достигнуто путем дополнительной настройки гиперпараметров, использования более сложных методов или увеличения объема данных для обучения.
